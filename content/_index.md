---
title: "Alan Jeffares"
description: "Alan Jeffares"
---

# Alan Jeffares

  <div class="profile-pic">
    <img src="/images/alan.webp" alt="profile" />
  </div>

I'm a 2nd year Machine Learning PhD student in the University of Cambridge at the [Department of Applied Mathematics](http://www.damtp.cam.ac.uk/). I am interested in building a better understanding of empirical phenomena in deep learning (e.g. double descent, loss landscapes) and developing methodological advances from these insights (e.g. deep ensembles). I hold an MSc in Machine Learning from [University College London](https://www.ucl.ac.uk/) and a BSc in Statistics from [University College Dublin](https://www.ucd.ie/). I have previously worked as a Data Scientist at [Accenture's global center for R&D innovation](https://www.accenture.com/il-en/services/about/innovation-hub-the-dock) and in the [Insight Research Center for Data Analytics](https://www.insight-centre.org/). To reach out, please send an email to: *aj659 [at] cam [dot] ac [dot] uk*.


{{% center %}}
[[twitter](https://twitter.com/Jeffaresalan)] [[scholar](https://scholar.google.com/citations?user=e65kJ08AAAAJ&hl=en)] [[github](https://github.com/alanjeffares)] [[linkedin](https://linkedin.com/in/alanjeffares)]
{{% /center %}}

---

## 🗞️ News 🗞️

* <span class="date">Sep 2023</span> &#8594; _Two papers accepted for_ [**NeurIPS2023**](https://nips.cc/)_!_ One **oral** (top <2% of submissions) that provides an alternative take on double descent suggesting that it may not be so contradictory from classic statistical notions of model complexity. Then, a **poster** that investigates if deep ensembles can be trained jointly rather than independently.

* <span class="date">Jan 2023</span> &#8594; _Two papers accepted!_ 🥳 One at [**AISTATS23**](https://virtual.aistats.org/Conferences/2023) ([[paper](https://proceedings.mlr.press/v206/seedat23a.html)]) and one at [**ICLR23**](https://iclr.cc/) ([[paper](https://openreview.net/forum?id=n6H86gW8u0d)]). These papers explore self-supervised learning for conformal prediction and a new regularizer for neural networks, respectively. I look forward to presenting these with my co-authors!

* <span class="date">April 2022</span> &#8594; I have officially started a PhD in Machine Learning in the University of Cambridge under the supervision of Mihaela van der Schaar! 

* <span class="date">Jan 2022</span> &#8594; _First paper accepted!_ 🎉 Work done during my masters thesis under the supervision of Timos Moraitis and Pontus Stenetorp has been accepted as a **spotlight** (top 5% of submissions) at **ICLR22**. This [paper](https://openreview.net/pdf?id=iMH1e5k7n3L) took a neuroscience inspired approach to improve the accuracy-efficiency trade-off in RNNs. 

* <span class="date">Dec 2021</span> &#8594; _Graduated_ 🎓 I have officially graduated with an MSc in Machine Learning from UCL. I was also a recipient of a Dean's list award for "outstanding academic performance". 


---

## 📚 Research 📚

Please find some of my publications below (a more up-to-date list can be found on [google scholar](https://scholar.google.com/citations?user=e65kJ08AAAAJ&hl=en)).

"\*" denotes equal contribution.

### Preprints

- A. Curth, <mark>A. Jeffares</mark>, M. van der Schaar. *Why do Random Forests Work? Understanding Tree Ensembles as Self-Regularizing Adaptive Smoothers*. [[preprint]](https://arxiv.org/abs/2402.01502)

### Conferences

- A. Curth*, <mark>A. Jeffares*</mark>, M. van der Schaar. *A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning*. **NeurIPS, 2023 - Oral (top <2%)**. [[paper]](https://openreview.net/forum?id=O0Lz8XZT2b) [[code]](https://github.com/alanjeffares/not-double-descent)
- <mark>A. Jeffares</mark>, T. Liu, J .Crabbé, M. van der Schaar. *Joint Training of Deep Ensembles Fails Due to Learner Collusion*. **NeurIPS, 2023** [[preprint]](https://arxiv.org/abs/2301.11323) [[paper]](https://openreview.net/forum?id=WpGLxnOWhn) [[code]](https://github.com/alanjeffares/joint-ensembles)
- N. Seedat*, <mark>A. Jeffares*</mark>, F. Imrie, M. van der Schaar. *Improving Adaptive Conformal Prediction Using Self-Supervised Learning*. **AISTATS, 2023** [[paper]](https://proceedings.mlr.press/v206/seedat23a.html) [[code]](https://github.com/seedatnabeel/SSCP)
- <mark>A. Jeffares*</mark>, T. Liu*, J. Crabbé, F. Imrie, M. van der Schaar. *TANGOS: Regularizing Tabular Neural Networks through Gradient Orthogonalization and Specialization*. **ICLR, 2023** [[paper]](https://openreview.net/forum?id=n6H86gW8u0d) [[code]](https://github.com/alanjeffares/TANGOS)
- <mark>A. Jeffares</mark>, Q. Guo, P. Stenetorp, T. Moraitis. *Spike-inspired rank coding for fast and accurate recurrent neural networks*. **ICLR, 2022 - Spotlight (top 5%)**. [[paper]](https://openreview.net/pdf?id=iMH1e5k7n3L) [[code]](https://github.com/NeuromorphicComputing/RankCoding)


